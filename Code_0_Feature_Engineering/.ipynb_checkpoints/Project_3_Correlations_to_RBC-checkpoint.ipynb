{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 3 - Predicting Daily Direction of RBC\"\n",
    "\n",
    "Similar to that in project 2 outlined in Project2_Correlations_to_BNS, the objective here:\n",
    "-   develop a ML model to predict the direction of movement for the RBC stock (whereas in project 2 this was for BNS stock)\n",
    "\n",
    "Process is identical as it was in Project2_Correlations_to_BNS and outlined below but again for RBC instead of BNS\n",
    "1. Load Security Data - January 1, 2014 to present\n",
    "    a. Model Development (5 Years): January 1, 2014 to December 31, 2018 \n",
    "    b. Model Application: January 1, 2019 to present\n",
    "2. Determine Highest Correlated Stocks by Daily Percent return\n",
    "    a. Shift: Number of Days\n",
    "    b. Duration: Number of Days\n",
    "3. Create Development Dataset\n",
    "    a. Top 15 Correlated Stocts\n",
    "    b. Percent Close: Close as a precent of high vs. low for the range\n",
    "    c. Rolling 30 Day Z score:\n",
    "    d. Rolling Correlation:# Project 2 - Predicting Daily Direction of RBC"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A. Import Python Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/Users/NatashaPredovic/Desktop/Project_3_Correlations_to_RBC.ipynb Cell 3\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/NatashaPredovic/Desktop/Project_3_Correlations_to_RBC.ipynb#W2sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mcsv\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/NatashaPredovic/Desktop/Project_3_Correlations_to_RBC.ipynb#W2sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m# Subsequent imports\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/NatashaPredovic/Desktop/Project_3_Correlations_to_RBC.ipynb#W2sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/NatashaPredovic/Desktop/Project_3_Correlations_to_RBC.ipynb#W2sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mseaborn\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39msns\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/NatashaPredovic/Desktop/Project_3_Correlations_to_RBC.ipynb#W2sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39myfinance\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39myf\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "# Initial imports\n",
    "import os\n",
    "import csv\n",
    "import requests\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "import alpaca_trade_api as tradeapi\n",
    "from MCForecastTools import MCSimulation\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "import datetime as dt\n",
    "\n",
    "# Subsequent imports\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import yfinance as yf\n",
    "import hvplot.pandas\n",
    "\n",
    "# Logistic Regression Libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression as lr\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "\n",
    "# Enable the Matplotlib property to allow diagrams to display in Jupyter Notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "B. Import Data - Security/Stock Prices\n",
    "B.1. Yahoo Finance Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List the ticker symbols for the stocks of interest\n",
    "lst_Stocks = ['RBC.TO', 'BMO.TO', 'CM.TO', 'NA.TO','RY.TO', 'TD.TO', 'ZEB.TO','ZWB.TO', 'XGB.TO', 'CL' ]\n",
    "\n",
    "# Create a List of Columns thare are not required (Keeping the Close)\n",
    "lst_DropColumns = [\"Open\", \"High\", \"Low\", \"Volume\", \"Adj Close\", \"Ticker\"]\n",
    "\n",
    "# Determine the Date range for the desired data\n",
    "start_date = '2014-01-01'\n",
    "end_date = '2022-12-31'\n",
    "\n",
    "# Create empty dataframe to hold stock data\n",
    "df_AllStocks_Yahoo=pd.DataFrame()\n",
    "\n",
    "# Gathers stock data from listed tickers and combines them into a dataframe\n",
    "for ticker in lst_Stocks:\n",
    "    # Create data frame from API in loop \n",
    "    df= yf.download(ticker, start= start_date, end= end_date)\n",
    "    # Remove to '.TO' suffix from Canadian stocks\n",
    "    tic= ticker.replace('.TO','')\n",
    "    df['Ticker']=tic\n",
    "    # Drop unwanted coloumns - Keep Adjusted Close\n",
    "    df.drop(columns = lst_DropColumns, inplace= True)\n",
    "    # Combine individual stocks into a single data frame\n",
    "    df_AllStocks_Yahoo=pd.concat([df_AllStocks_Yahoo, df], axis= 1)\n",
    "\n",
    "# Delete temporary Dataframe\n",
    "del(df)    \n",
    "\n",
    "# Rename the coloumns to the ticker symbols in the list\n",
    "df_AllStocks_Yahoo.columns = lst_Stocks\n",
    "\n",
    "# Drop the N/As\n",
    "df_AllStocks_Yahoo = df_AllStocks_Yahoo.dropna()\n",
    "\n",
    "# Add label to index\n",
    "df_AllStocks_Yahoo = df_AllStocks_Yahoo.reset_index()\n",
    "df_AllStocks_Yahoo['Date']=pd.to_datetime(df_AllStocks_Yahoo['Date']).dt.date\n",
    "df_AllStocks_Yahoo=df_AllStocks_Yahoo.set_index(['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the data\n",
    "display(df_AllStocks_Yahoo)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "B.2. CSV Import - Trade Station Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Commodities\n",
    "path_cd = Path(\"../data/CD_10Year.txt\")\n",
    "path_dx = Path(\"../data/DX_10Year.txt\")\n",
    "\n",
    "# Create a List of Columns thare are not required (Keeping the Close)\n",
    "lst_DropColumns = ['Time', 'Open', 'High', 'Low', 'Vol', 'OI']\n",
    "\n",
    "# Commodities\n",
    "# USD - CAD\n",
    "df_cd = pd.read_csv(path_cd, index_col = \"Date\", parse_dates = True, infer_datetime_format=True)\n",
    "df_cd = df_cd.drop(columns = lst_DropColumns)\n",
    "df_cd.columns = [\"USDCAD\"]\n",
    "df_cd['USDCAD'] = df_cd['USDCAD'].copy() * 100   # Upscale to common order of magnitude\n",
    "df_cd = df_cd.reset_index()\n",
    "df_cd = df_cd.dropna()\n",
    "df_cd = df_cd.set_index(['Date'])\n",
    "\n",
    "# USD Index\n",
    "df_dx = pd.read_csv(path_dx, index_col = \"Date\", parse_dates = True, infer_datetime_format=True)\n",
    "df_dx = df_dx.drop(columns = lst_DropColumns)\n",
    "df_dx.columns = [\"DXY\"]\n",
    "df_dx = df_dx.reset_index()\n",
    "df_dx = df_dx.set_index(['Date'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "B.3. Concatinate Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join Yahoo Finance and Trade Station CSV files.\n",
    "df_all_stocks_close = pd.concat([df_AllStocks_Yahoo, df_cd, df_dx], axis=\"columns\", join=\"inner\")\n",
    "df_all_stocks_close = df_all_stocks_close.dropna()\n",
    "\n",
    "\n",
    "# Ensure data sorted by index \n",
    "#df_all_stocks_close.index.name = 'Date'\n",
    "df_all_stocks_close.sort_index(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display sample data\n",
    "display(df_all_stocks_close)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "B.4. Daily Returns\n",
    "B.4.i. Daily Returns: Create Daily Returns Dataframe from Daily Close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Daily Returns\n",
    "# Drop nulls\n",
    "df_all_stocks_daily_returns = df_all_stocks_close.pct_change().dropna().copy()\n",
    "\n",
    "# Display sample data\n",
    "df_all_stocks_daily_returns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C. Prepare Data for Analysis\n",
    "C.1. Dataframe Column Names to List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_variables = df_all_stocks_daily_returns.columns.to_list()\n",
    "print(len(lst_variables))\n",
    "print(type(lst_variables))\n",
    "print(lst_variables)\n",
    "print(df_all_stocks_daily_returns.index.name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C.3. Analysis Routine - Looking for Correlation between the Feature (x) and Target (y) Variables (securities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through all securities as a leading indicator:\n",
    "index_count = 0\n",
    "\n",
    "df_correlation = pd.DataFrame(columns = ['Target_Change','Target_Shift', 'Feature_Change', 'Feature(x)', 'Target(y)', 'Corr', 'AbsCorr'\n",
    "                                         , 'train_accuracy', 'train_reall_0', 'train_reall_1', 'train_precision_0', 'train_precision_1'\n",
    "                                         , 'test_accuracy', 'test_recall_0','test_recall_1', 'test_precision_0', 'test_precision_1'])\n",
    "\n",
    "# Loop through all securities as a leading indicator:\n",
    "for feature_x in lst_variables:\n",
    "    lst2 = lst_variables.copy()\n",
    "    lst2.remove(feature_x)\n",
    "    \n",
    "# Loop through all stosck excluding the lerading indicator:    \n",
    "    #for target in lst2:\n",
    "    target_y = 'RBC'\n",
    "    \n",
    "# Create and empty DataFrame for closing prices\n",
    "    df_closing_prices = pd.DataFrame()\n",
    "\n",
    "# Fetch the closing prices of Stock being lead\n",
    "    df_closing_prices[feature_x] = df_all_stocks_daily_returns[feature_x]\n",
    "    df_closing_prices[target_y] = df_all_stocks_daily_returns[target_y]\n",
    "\n",
    "# Calcualte for Leader Stock\n",
    "        #df_closing_prices['leader_moving_average']=df_closing_prices[leader].rolling(window=5).mean()\n",
    "        #df_closing_prices['leader_tstat']=(df_closing_prices[leader]-df_closing_prices['leader_moving_average'])/df_closing_prices[leader].rolling(window=200).std()\n",
    "        #df_closing_prices['leader_pct_chg']=df_closing_prices[leader].pct_change()\n",
    "        #df_closing_prices['target_moving_average']=df_closing_prices[target].rolling(window=5).mean()\n",
    "\n",
    "# Drop columns not required --> 43 aka 42 is the answer to the ultimate question about life the uninvers ans everything. \n",
    "    df_closing_prices=df_closing_prices.dropna()\n",
    "    target_change = 7\n",
    "    for target_shift in range(target_change + 1, 43, 1):\n",
    "        for feature_change in range(1, 43, 1):\n",
    "            #print('***************************************************************************************************')\n",
    "            #print(f'Index: {index_count} Iteration {target_shift} for interval {feature_change} Feature(x): {feature_x} vs. Target(Y): {target_y}')\n",
    "            #print('***************************************************************************************************')\n",
    "            dfopt=df_closing_prices\n",
    "            dfopt['pctChange']=dfopt[target_y].pct_change(target_change)\n",
    "            dfopt['Target_Change']=dfopt[target_y].pct_change(target_change).shift(-target_shift)\n",
    "            dfopt['Feature_Change']=dfopt[feature_x].pct_change(feature_change)\n",
    "            dfopt=dfopt[['Target_Change','Feature_Change']]\n",
    "            dfcorr = dfopt.corr() \n",
    "            #display(dfopt.corr())\n",
    "            \n",
    "# **********************************************************************************************************\n",
    "# Logistic Regresssion Model\n",
    "# **********************************************************************************************************\n",
    "            # Conver Div by Zero to NA and Droip NA\n",
    "            dfopt.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "            dfopt=dfopt.dropna()\n",
    "\n",
    "# Set target variabler to 1 for increas and 0 for decrease\n",
    "            dfopt['y'] = np.where(dfopt['Target_Change'] >=0, 1, 0)\n",
    "            \n",
    "# Set A and Y variables for model\n",
    "            Y = dfopt['y']\n",
    "            X = dfopt.drop(columns = ['y','Target_Change'])\n",
    "                        \n",
    "# Perform Train Test Split @70/30\n",
    "            X_train, X_test, Y_train, Y_test = train_test_split(X,Y,random_state =1, stratify=Y, test_size = 0.30)\n",
    "            \n",
    "# Creat Model\n",
    "            classifier = lr(solver='lbfgs', random_state = 1)\n",
    "            classifier.fit(X_train, Y_train)\n",
    "            predictions_train=classifier.predict(X_train)\n",
    "            predictions_test=classifier.predict(X_test)\n",
    "            \n",
    "# Add predictions to Datadrame            \n",
    "            df_prediction_train = pd.DataFrame({\"prediction\":predictions_train,\"actual\":Y_train} )\n",
    "            df_prediction_test = pd.DataFrame({\"prediction\":predictions_test,\"actual\":Y_test} )\n",
    "            \n",
    "# Logistic Regression reports\n",
    "            Test_Report = classification_report_imbalanced(Y_test,predictions_test)\n",
    "            Test_Matrix = confusion_matrix(Y_test,predictions_test)\n",
    "            #print(Test_Report) \n",
    "            #print(Test_Matrix) \n",
    "\n",
    "#sklearn.metrics.accuracy_score(y_true, y_pred, *, normalize=True, sample_weight=None)[source]Â¶\n",
    "            train_accuracy =  accuracy_score(df_prediction_train['actual'], df_prediction_train['prediction'])\n",
    "            test_accuracy =  accuracy_score(df_prediction_test['actual'], df_prediction_test['prediction'])\n",
    "#sklearn.metrics.recall_score(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')[source]\n",
    "            train_recall = recall_score(df_prediction_train['actual'], df_prediction_train['prediction'], average=None)\n",
    "            test_recall = recall_score(df_prediction_test['actual'], df_prediction_test['prediction'], average=None)\n",
    "#sklearn.metrics.precision_score(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')[source]            \n",
    "            train_precision = precision_score(df_prediction_train['actual'], df_prediction_train['prediction'], average=None)\n",
    "            test_precision = precision_score(df_prediction_test['actual'], df_prediction_test['prediction'], average=None)\n",
    "            \n",
    "# Put correlation into a dataframe            \n",
    "            df_temp = pd.DataFrame({\"Target_Change\":[target_change], \"Target_Shift\":[target_shift], \"Feature_Change\":[feature_change], \"Feature(x)\":feature_x, \"Target(y)\":target_y, \"Corr\":dfcorr.iloc[0][1], \"AbsCorr\": abs(dfcorr.iloc[0][1])\n",
    "                                    , \"train_accuracy\":train_accuracy, \"train_reall_0\":train_recall[0], \"train_reall_1\":train_recall[1], \"train_precision_0\":train_precision[0], \"train_precision_1\":train_precision[1]\n",
    "                                    , \"test_accuracy\":test_accuracy, \"test_recall_0\":test_recall[0], \"test_recall_1\":test_recall[1], \"test_precision_0\":test_precision[0], \"test_precision_1\":test_precision[1]}, index = [index_count])\n",
    "          \n",
    "            df_correlation = pd.concat([df_correlation,df_temp], axis = \"rows\")\n",
    "            index_count += 1\n",
    "\n",
    "        del(dfopt)\n",
    "        #del(dfPlot) df.rank(method='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display Result\n",
    "display(df_correlation.shape)\n",
    "display(df_correlation.sort_values('AbsCorr', ascending=[False]).head(30))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
